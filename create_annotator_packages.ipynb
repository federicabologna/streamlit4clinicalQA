{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.getcwd()\n",
    "data_dir = os.path.join(dir, 'data')\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "output_dir = os.path.join(dir, 'output')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Annotator1',\n",
       " 'Annotator6',\n",
       " 'Annotator2',\n",
       " 'Annotator3',\n",
       " 'Annotator4',\n",
       " 'Annotator5']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(17)\n",
    "\n",
    "annotators = [f\"Annotator{i+1}\" for i in range(6)]\n",
    "random.shuffle(annotators)\n",
    "annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_dict_0 = {'coarse': [0, 50],\n",
    "                 'fine': [50, 100]}\n",
    "\n",
    "indexes_dict_1 = {'coarse': [50, 100],\n",
    "                 'fine': [0, 50]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, \":orange[This is the first sentence.] Here's the second one! Is this the third sentence? Yes, it is.\")\n",
      "(1, \"This is the first sentence. :orange[Here's the second one!] Is this the third sentence? Yes, it is.\")\n",
      "(2, \"This is the first sentence. Here's the second one! :orange[Is this the third sentence?] Yes, it is.\")\n",
      "(3, \"This is the first sentence. Here's the second one! Is this the third sentence? :orange[Yes, it is.]\")\n"
     ]
    }
   ],
   "source": [
    "def bold_sentences(text):\n",
    "    \n",
    "    # Load the spaCy English model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    # Process the text with spaCy to segment into sentences\n",
    "    doc = nlp(text)\n",
    "    sentences = [sentence.text for sentence in doc.sents]\n",
    "    fine_sentences = []\n",
    "    for bold_index in range(len(sentences)):\n",
    "        bold_sentence = f':orange[{sentences[bold_index]}]'\n",
    "        new_sentences = sentences[:bold_index] + [bold_sentence] + sentences[bold_index + 1:]\n",
    "        fine_sentence = ' '.join(new_sentences)\n",
    "        fine_sentences.append((bold_index, fine_sentence))\n",
    "    \n",
    "    return fine_sentences\n",
    "\n",
    "# Example text\n",
    "text = \"\"\"This is the first sentence. Here's the second one! Is this the third sentence? Yes, it is.\"\"\"\n",
    "\n",
    "# bold sentences in the example text\n",
    "for i in bold_sentences(text):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, f\"gpt4_answers.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    gpt4_answers = [json.loads(line) for line in jsonl_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, f\"llama_answers.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    llama_answers = [json.loads(line) for line in jsonl_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, f\"physician_answers.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    physician_answers = [json.loads(line) for line in jsonl_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotator1\n",
      "{'coarse': [0, 50], 'fine': [50, 100]}\n",
      "Adding coarse annotations, indexes: [0, 50]\n",
      "Adding fine annotations, indexes: [50, 100]\n",
      "Annotator6\n",
      "{'coarse': [0, 50], 'fine': [50, 100]}\n",
      "Adding coarse annotations, indexes: [0, 50]\n",
      "Adding fine annotations, indexes: [50, 100]\n",
      "Annotator2\n",
      "{'coarse': [0, 50], 'fine': [50, 100]}\n",
      "Adding coarse annotations, indexes: [0, 50]\n",
      "Adding fine annotations, indexes: [50, 100]\n",
      "Annotator3\n",
      "{'coarse': [50, 100], 'fine': [0, 50]}\n",
      "Adding coarse annotations, indexes: [50, 100]\n",
      "Adding fine annotations, indexes: [0, 50]\n",
      "Annotator4\n",
      "{'coarse': [50, 100], 'fine': [0, 50]}\n",
      "Adding coarse annotations, indexes: [50, 100]\n",
      "Adding fine annotations, indexes: [0, 50]\n",
      "Annotator5\n",
      "{'coarse': [50, 100], 'fine': [0, 50]}\n",
      "Adding coarse annotations, indexes: [50, 100]\n",
      "Adding fine annotations, indexes: [0, 50]\n"
     ]
    }
   ],
   "source": [
    "flag = 0\n",
    "for annotator in annotators:\n",
    "    \n",
    "    print(annotator)\n",
    "    \n",
    "    if flag < 3:\n",
    "        indexes_dictionary = indexes_dict_0\n",
    "    else:\n",
    "        indexes_dictionary = indexes_dict_1\n",
    "    \n",
    "    print(indexes_dictionary)\n",
    "        \n",
    "    for annotation_type, indexes in indexes_dictionary.items():\n",
    "        \n",
    "        print(f'Adding {annotation_type} annotations, indexes: {indexes}')\n",
    "        \n",
    "        for n in range(indexes[0], indexes[1]):\n",
    "            \n",
    "            qa_pairs = [gpt4_answers[n], llama_answers[n], physician_answers[n]]\n",
    "            random.shuffle(qa_pairs)\n",
    "            \n",
    "            if qa_pairs[0]['question_id'] == qa_pairs[1]['question_id'] == qa_pairs[2]['question_id']:\n",
    "            \n",
    "                for qa_pair in qa_pairs:\n",
    "                    \n",
    "                    if annotation_type == 'coarse':\n",
    "                        qa_pair['annotation_type'] = annotation_type\n",
    "                        qa_pair['rated'] = 'No'\n",
    "                    \n",
    "                        with open(os.path.join(output_dir, f'{annotator.lower()}_{annotation_type}.jsonl'), 'a') as file:\n",
    "                                json.dump(qa_pair, file)\n",
    "                                file.write('\\n')\n",
    "                \n",
    "                    elif annotation_type == 'fine':\n",
    "                        sentences = bold_sentences(qa_pair['answer'])\n",
    "                        for sentence in sentences:\n",
    "                            new_d = qa_pair.copy()\n",
    "                            new_d['annotation_type'] = annotation_type\n",
    "                            new_d['rated'] = 'No'\n",
    "                            new_d['sentence_id'] = new_d['answer_id'] + f'_{sentence[0]}'\n",
    "                            new_d['answer'] = sentence[1]\n",
    "                            with open(os.path.join(output_dir, f'{annotator.lower()}_{annotation_type}.jsonl'), 'a') as file:\n",
    "                                json.dump(new_d, file)\n",
    "                                file.write('\\n')\n",
    "\n",
    "    flag += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, f\"annotator3_coarse.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    data = [json.loads(line) for line in jsonl_file]\n",
    "    \n",
    "for d in data:\n",
    "    if int(d['question_id'].split('_')[1]) == 145:\n",
    "        print(d['answer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
