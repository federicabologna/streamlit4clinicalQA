{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dir = os.getcwd()\n",
    "data_dir = os.path.join(dir, 'data')\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "output_dir = os.path.join(dir, 'output')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, f\"gpt4_answers.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    gpt4_answers = [json.loads(line) for line in jsonl_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, f\"llama_answers.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    llama_answers = [json.loads(line) for line in jsonl_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, f\"physician_answers.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    physician_answers = [json.loads(line) for line in jsonl_file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Coarse Part 1 and Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Annotator1',\n",
       " 'Annotator6',\n",
       " 'Annotator2',\n",
       " 'Annotator3',\n",
       " 'Annotator4',\n",
       " 'Annotator5']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomizing which author is in which group:\n",
    "# the first three authors do annotations 0-50 with coarse style\n",
    "# the second three authors do annotations 51-100 with fine style\n",
    "random.seed(17)\n",
    "\n",
    "annotators = [f\"Annotator{i+1}\" for i in range(6)]\n",
    "random.shuffle(annotators)\n",
    "annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_dict = {'group0' : {'coarse': [0, 50],\n",
    "                            'fine': [50, 100]},\n",
    "                'group1' : {'coarse': [50, 100],\n",
    "                            'fine': [0, 50]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotator1\n",
      "{'coarse': [0, 50], 'fine': [50, 100]}\n",
      "Adding coarse annotations, indexes: [0, 50]\n",
      "Adding fine annotations, indexes: [50, 100]\n",
      "Annotator6\n",
      "{'coarse': [0, 50], 'fine': [50, 100]}\n",
      "Adding coarse annotations, indexes: [0, 50]\n",
      "Adding fine annotations, indexes: [50, 100]\n",
      "Annotator2\n",
      "{'coarse': [0, 50], 'fine': [50, 100]}\n",
      "Adding coarse annotations, indexes: [0, 50]\n",
      "Adding fine annotations, indexes: [50, 100]\n",
      "Annotator3\n",
      "{'coarse': [50, 100], 'fine': [0, 50]}\n",
      "Adding coarse annotations, indexes: [50, 100]\n",
      "Adding fine annotations, indexes: [0, 50]\n",
      "Annotator4\n",
      "{'coarse': [50, 100], 'fine': [0, 50]}\n",
      "Adding coarse annotations, indexes: [50, 100]\n",
      "Adding fine annotations, indexes: [0, 50]\n",
      "Annotator5\n",
      "{'coarse': [50, 100], 'fine': [0, 50]}\n",
      "Adding coarse annotations, indexes: [50, 100]\n",
      "Adding fine annotations, indexes: [0, 50]\n"
     ]
    }
   ],
   "source": [
    "flag = 0\n",
    "for annotator in annotators:\n",
    "    \n",
    "    print(annotator)\n",
    "    \n",
    "    if flag < 3:\n",
    "        indexes_dictionary = indexes_dict['group0']\n",
    "    else:\n",
    "        indexes_dictionary = indexes_dict['group1']\n",
    "    \n",
    "    print(indexes_dictionary)\n",
    "        \n",
    "    for annotation_type, indexes in indexes_dictionary.items():\n",
    "        \n",
    "        print(f'Adding {annotation_type} annotations, indexes: {indexes}')\n",
    "        \n",
    "        question_positions = list(range(indexes[0], indexes[1])) # positions of the questions in the jsonl files that store questions and answers\n",
    "        random.shuffle(question_positions) # Randomize question order but randomizing order of indexes \n",
    "\n",
    "        # Split questions into batches of 3\n",
    "        batches = {}\n",
    "        batch_n = 1\n",
    "        for i in range(0, len(question_positions), 3):\n",
    "            key = f'batch_{batch_n}'\n",
    "            batches[key] = question_positions[i:i+3]\n",
    "            batch_n += 1\n",
    "        \n",
    "        for batch_id, positions in batches.items():\n",
    "            \n",
    "            for n in positions:\n",
    "                \n",
    "                qa_pairs = [gpt4_answers[n], llama_answers[n], physician_answers[n]] # Randomizing answer type order\n",
    "                random.shuffle(qa_pairs)\n",
    "                \n",
    "                if qa_pairs[0]['question_id'] == qa_pairs[1]['question_id'] == qa_pairs[2]['question_id']:\n",
    "                \n",
    "                    for qa_pair in qa_pairs:\n",
    "                        \n",
    "                        if annotation_type == 'coarse':\n",
    "                            qa_pair['annotation_type'] = annotation_type\n",
    "                            qa_pair['rated'] = 'No'\n",
    "                            qa_pair['batch_id'] = batch_id\n",
    "                        \n",
    "                            # with open(os.path.join(output_dir, 'all', f'{annotator.lower()}_{annotation_type}.jsonl'), 'a') as file:\n",
    "                            #         json.dump(qa_pair, file)\n",
    "                            #         file.write('\\n')\n",
    "                    \n",
    "                        # elif annotation_type == 'fine':\n",
    "                            \n",
    "                        #     sentences = bold_sentences(qa_pair['answer'])\n",
    "                            \n",
    "                        #     for sentence in sentences:\n",
    "                        #         new_d = qa_pair.copy()\n",
    "                        #         new_d['annotation_type'] = annotation_type\n",
    "                        #         new_d['rated'] = 'No'\n",
    "                        #         new_d['batch_id'] = batch_id\n",
    "                        #         new_d['sentence_id'] = new_d['answer_id'] + f'_{sentence[0]}'\n",
    "                        #         new_d['answer'] = sentence[1]\n",
    "                        #         with open(os.path.join(output_dir, 'all', f'{annotator.lower()}_{annotation_type}.jsonl'), 'a') as file:\n",
    "                        #             json.dump(new_d, file)\n",
    "                        #             file.write('\\n')\n",
    "\n",
    "    flag += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Fine Part 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with numbered lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt4_0',\n",
       " 'gpt4_10',\n",
       " 'gpt4_13',\n",
       " 'gpt4_14',\n",
       " 'gpt4_15',\n",
       " 'gpt4_17',\n",
       " 'gpt4_18',\n",
       " 'gpt4_19',\n",
       " 'gpt4_2',\n",
       " 'gpt4_3',\n",
       " 'gpt4_30',\n",
       " 'gpt4_35',\n",
       " 'gpt4_36',\n",
       " 'gpt4_47',\n",
       " 'gpt4_56',\n",
       " 'gpt4_68',\n",
       " 'gpt4_72',\n",
       " 'gpt4_73',\n",
       " 'gpt4_81',\n",
       " 'gpt4_87',\n",
       " 'gpt4_88',\n",
       " 'gpt4_92',\n",
       " 'llama_0',\n",
       " 'llama_1',\n",
       " 'llama_10',\n",
       " 'llama_11',\n",
       " 'llama_13',\n",
       " 'llama_14',\n",
       " 'llama_15',\n",
       " 'llama_17',\n",
       " 'llama_18',\n",
       " 'llama_19',\n",
       " 'llama_20',\n",
       " 'llama_24',\n",
       " 'llama_27',\n",
       " 'llama_30',\n",
       " 'llama_31',\n",
       " 'llama_32',\n",
       " 'llama_34',\n",
       " 'llama_35',\n",
       " 'llama_36',\n",
       " 'llama_4',\n",
       " 'llama_43',\n",
       " 'llama_44',\n",
       " 'llama_47',\n",
       " 'llama_49',\n",
       " 'llama_5',\n",
       " 'llama_51',\n",
       " 'llama_52',\n",
       " 'llama_53',\n",
       " 'llama_54',\n",
       " 'llama_55',\n",
       " 'llama_56',\n",
       " 'llama_57',\n",
       " 'llama_59',\n",
       " 'llama_6',\n",
       " 'llama_61',\n",
       " 'llama_63',\n",
       " 'llama_64',\n",
       " 'llama_65',\n",
       " 'llama_66',\n",
       " 'llama_67',\n",
       " 'llama_68',\n",
       " 'llama_69',\n",
       " 'llama_7',\n",
       " 'llama_70',\n",
       " 'llama_71',\n",
       " 'llama_72',\n",
       " 'llama_73',\n",
       " 'llama_74',\n",
       " 'llama_76',\n",
       " 'llama_78',\n",
       " 'llama_79',\n",
       " 'llama_84',\n",
       " 'llama_85',\n",
       " 'llama_86',\n",
       " 'llama_87',\n",
       " 'llama_88',\n",
       " 'llama_89',\n",
       " 'llama_9',\n",
       " 'llama_91',\n",
       " 'llama_92',\n",
       " 'llama_93',\n",
       " 'llama_94',\n",
       " 'llama_95',\n",
       " 'llama_99'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrong = []\n",
    "for l in [gpt4_answers, llama_answers]:\n",
    "    for d in l:\n",
    "        if \"\\n\\n1.\" in d['answer'] or '\\n\\n' in d['answer'] or \"\\n*\" in d['answer'] or '**' in d['answer']:\n",
    "            wrong.append(d['answer_id'])\n",
    "set(wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(set(wrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the text with spaCy to segment into sentences\n",
    "wrong_ones = []\n",
    "for n in [1,3]:\n",
    "    \n",
    "    with open(os.path.join(output_dir, 'all',f'annotator{n}_coarse.jsonl'), 'r', encoding='utf-8') as jsonl_file:\n",
    "        data = [json.loads(line) for line in jsonl_file]\n",
    "        \n",
    "        for d in data:\n",
    "            if d['answer_id'] in set(wrong):\n",
    "                new_d = {'answer_id': d['answer_id'],\n",
    "                        'answer': d['answer']}\n",
    "                wrong_ones.append(new_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in wrong_ones:\n",
    "    text = d['answer']\n",
    "    text = text.replace(\". \", \". #\")\n",
    "    text = text.replace(\"\\n- \", \"#\\n- #\")\n",
    "    text = text.replace(\"\\n* \", \"#\\n* #\")\n",
    "    text = text.replace(\"\\n\\n\", \"#\\n\\n#\")\n",
    "    d['answer'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, \":orange[This is the first sentence. ] \\n\\n1. And another sentence. \\n\\n Here's the second one!  Is this the third sentence? Yes, it is.\")\n",
      "(1, \"This is the first sentence.  \\n\\n1. :orange[And another sentence.] \\n\\n Here's the second one!  Is this the third sentence? Yes, it is.\")\n",
      "(2, \"This is the first sentence.  \\n\\n1. And another sentence. \\n\\n :orange[Here's the second one! ] Is this the third sentence? Yes, it is.\")\n",
      "(3, \"This is the first sentence.  \\n\\n1. And another sentence. \\n\\n Here's the second one!  :orange[Is this the third sentence? Yes, it is.]\")\n"
     ]
    }
   ],
   "source": [
    "def special_bolding(text):\n",
    "\n",
    "    sentences = text.split(\"#\")\n",
    "    \n",
    "    fine_sentences = []\n",
    "    for bold_index in range(len(sentences)):\n",
    "        if len(sentences[bold_index]) > 5:\n",
    "            bold_sentence = f':orange[{sentences[bold_index]}]'\n",
    "            new_sentences = sentences[:bold_index] + [bold_sentence] + sentences[bold_index + 1:]\n",
    "            # print('new sentences!')\n",
    "            # print(new_sentences)\n",
    "            fine_sentence = ' '.join(new_sentences)\n",
    "            clean_sentence = re.sub(r\"\\n([2-7]\\. )\\]\", r\"]\\n\\1\", fine_sentence)\n",
    "            fine_sentences.append((len(fine_sentences), clean_sentence))\n",
    "\n",
    "    return fine_sentences\n",
    "\n",
    "# Example text\n",
    "text = \"\"\"This is the first sentence. #\\n\\n1.#And another sentence.#\\n\\n#Here's the second one! #Is this the third sentence? Yes, it is.\"\"\"\n",
    "\n",
    "# bold sentences in the example text\n",
    "for i in special_bolding(text):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in wrong_ones:\n",
    "    for version in special_bolding(d['answer']):\n",
    "        new_d = {'text': version[1]}\n",
    "        # with open(os.path.join(f'test.jsonl'), 'a') as file:\n",
    "        #     json.dump(new_d, file)\n",
    "        #     file.write('\\n')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_ones_dict = {}\n",
    "for d in wrong_ones:\n",
    "    answer_id = d['answer_id']\n",
    "    wrong_ones_dict[answer_id] = special_bolding(d['answer'])\n",
    "    \n",
    "# with open(os.path.join('data', f'wrong_ones.json'), 'w') as file:\n",
    "#     json.dump(wrong_ones_dict, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"A white tongue can be caused by several conditions, some of which are benign and easily treatable, while others may require more comprehensive medical intervention. #Common causes include:#\\n\\n#1. #Oral hygiene: Poor oral hygiene can lead to a buildup of bacteria and debris on the tongue, presenting as a white coating.\\n2. #Dehydration or dry mouth: This can cause the surface of the tongue to appear white due to decreased saliva production.\\n3. #Oral thrush: This is a fungal infection caused by Candida yeast, leading to white, creamy patches on the tongue and inside the mouth.\\n4. #Leukoplakia: This condition involves thick, white patches on the tongue and is often associated with smoking or other irritants. #It can sometimes be a precancerous condition.\\n5. #Smoking and alcohol use: Both can contribute to changes in the color and texture of the tongue.#\\n\\n#If the white tongue persists, it's advisable to consult a healthcare provider to diagnose the underlying cause and receive appropriate treatment.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong_ones_df.to_csv(\"wrong_ones.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join('data', 'wrong_ones.json'), 'r') as json_file:\n",
    "#     wrong_ones = json.load(json_file)\n",
    "\n",
    "# new_wrong_ones = {}\n",
    "# for answer_id, sentences in wrong_ones.items():\n",
    "#     new_sentences = []\n",
    "#     for number, sentence in sentences:\n",
    "#         new_sentence = sentence.replace(\":orange[\", \"<mark>\").replace(\"]\", \"</mark>\")\n",
    "#         new_sentences.append([number, new_sentence])\n",
    "#     new_wrong_ones[answer_id] = new_sentences\n",
    "\n",
    "# with open(os.path.join('data', f'new_wrong_ones.json'), 'w') as file:\n",
    "#     json.dump(new_wrong_ones, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to split and highlight sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_short_sentences(sentences, min_length=30):\n",
    "    merged = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(sentences):\n",
    "        current = sentences[i]\n",
    "        if len(current) < min_length and '\\n\\n' not in current and i + 1 < len(sentences):\n",
    "            # Merge with the next sentence\n",
    "            merged_sentence = current.strip() + \" \" + sentences[i + 1].strip()\n",
    "            merged.append(merged_sentence)\n",
    "            i += 2  # Skip the next one since it's been merged\n",
    "        else:\n",
    "            merged.append(current)\n",
    "            i += 1\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_fine_sentence(text):\n",
    "\n",
    "    # Replace \"\\n\\n]\" with \"]\\n\\n\"\n",
    "    text = text.replace(\"\\n\\n]\", \"]\\n\\n\")\n",
    "    # Replace \"\\n]\" with \"]\\n\"\n",
    "    text = text.replace(\"\\n]\", \"]\\n\")\n",
    "    # Replace \"\\n\\nX.]\" with \"]\\n\\nX.\" where X is 1â€“7\n",
    "    text = re.sub(r'\\n\\n([1-7])\\.\\]', r']\\n\\n\\1.', text)\n",
    "    # Replace \":orange[X.\" with \"X. :orange[\" where X is a number between 1 and 7\n",
    "    re.sub(r':orange\\[(?P<num>[1-7])\\. (.*?)\\]', r'\\g<num>. :orange[\\2]', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, \"<mark>This is the first sentence. Here's the second one!</mark> Is this the third sentence? Yes, it is.\")\n",
      "(1, \"This is the first sentence. Here's the second one! <mark>Is this the third sentence? Yes, it is.</mark>\")\n"
     ]
    }
   ],
   "source": [
    "def bold_sentences(text):\n",
    "    \n",
    "    # Load the spaCy English model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    # Process the text with spaCy to segment into sentences\n",
    "    doc = nlp(text)\n",
    "    split_sentences = [sentence.text for sentence in doc.sents if len(sentence.text)>5]\n",
    "    # print(split_sentences)\n",
    "    sentences = merge_short_sentences(split_sentences)\n",
    "    # print(sentences)\n",
    "        \n",
    "    fine_sentences = []\n",
    "    for bold_index in range(len(sentences)):\n",
    "        bold_sentence = f'<mark>{sentences[bold_index]}</mark>'\n",
    "        new_sentences = sentences[:bold_index] + [bold_sentence] + sentences[bold_index + 1:]\n",
    "        # print('new sentences!')\n",
    "        # print(new_sentences)\n",
    "        fine_sentence = ' '.join(new_sentences)\n",
    "        clean_sentence = clean_fine_sentence(fine_sentence)\n",
    "        fine_sentences.append((bold_index, clean_sentence))\n",
    "    \n",
    "    return fine_sentences\n",
    "\n",
    "# Example text\n",
    "text = \"\"\"This is the first sentence. Here's the second one! Is this the third sentence? Yes, it is.\"\"\"\n",
    "\n",
    "# bold sentences in the example text\n",
    "for i in bold_sentences(text):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting pieces together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotator1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "23\n",
      "annotator2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "23\n",
      "annotator3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "23\n",
      "annotator4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "23\n",
      "annotator5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "23\n",
      "annotator6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "random.seed(17)\n",
    "\n",
    "with open(os.path.join('data', 'fine_part_2.json'), 'r') as json_file:\n",
    "    fine_questions = json.load(json_file)\n",
    "\n",
    "fine_questions_batches = {}\n",
    "for annotator, questions in fine_questions.items():\n",
    "    fine_questions_batches[annotator] = {}\n",
    "    batch_n = 1\n",
    "    question_list = fine_questions[annotator].copy()\n",
    "    random.shuffle(question_list)\n",
    "    for i in range(0, len(question_list), 3):\n",
    "            key = f'batch_{batch_n}'\n",
    "            fine_questions_batches[annotator][key] = question_list[i:i+3]\n",
    "            batch_n += 1\n",
    "\n",
    "for annotator, batches in fine_questions_batches.items():\n",
    "    print(annotator)\n",
    "    total = 0\n",
    "    for batch, questions in batches.items():\n",
    "        print(len(questions))\n",
    "        total += len(questions)\n",
    "    print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'new_wrong_ones.json'), 'r') as json_file:\n",
    "    new_wrong_ones = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lengths = []\n",
    "# for l in [gpt4_answers, llama_answers, physician_answers]:\n",
    "#     for qa_pair in l:\n",
    "#         if qa_pair['answer_id'] in wrong_ones.keys():\n",
    "#             key = qa_pair['answer_id']\n",
    "#             sentences = wrong_ones[key]\n",
    "        \n",
    "#         else:\n",
    "#             sentences = bold_sentences(qa_pair['answer'])\n",
    "            \n",
    "#         d ={'answer_id': qa_pair['answer'],\n",
    "#             'length': len(sentences)}\n",
    "        \n",
    "#         lengths.append(d)\n",
    "\n",
    "# lengths_df = pd.DataFrame(lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    300.000000\n",
       "mean       5.716667\n",
       "std        2.481313\n",
       "min        1.000000\n",
       "25%        4.000000\n",
       "50%        5.000000\n",
       "75%        7.000000\n",
       "max       15.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lengths_df['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_78': [0, 'gpt4_0'],\n",
       " 'question_24': [1, 'gpt4_1'],\n",
       " 'question_6': [2, 'gpt4_2'],\n",
       " 'question_156': [3, 'gpt4_3'],\n",
       " 'question_82': [4, 'gpt4_4'],\n",
       " 'question_112': [5, 'gpt4_5'],\n",
       " 'question_101': [6, 'gpt4_6'],\n",
       " 'question_139': [7, 'gpt4_7'],\n",
       " 'question_95': [8, 'gpt4_8'],\n",
       " 'question_36': [9, 'gpt4_9'],\n",
       " 'question_190': [10, 'gpt4_10'],\n",
       " 'question_52': [11, 'gpt4_11'],\n",
       " 'question_71': [12, 'gpt4_12'],\n",
       " 'question_117': [13, 'gpt4_13'],\n",
       " 'question_4': [14, 'gpt4_14'],\n",
       " 'question_59': [15, 'gpt4_15'],\n",
       " 'question_163': [16, 'gpt4_16'],\n",
       " 'question_120': [17, 'gpt4_17'],\n",
       " 'question_8': [18, 'gpt4_18'],\n",
       " 'question_30': [19, 'gpt4_19'],\n",
       " 'question_199': [20, 'gpt4_20'],\n",
       " 'question_131': [21, 'gpt4_21'],\n",
       " 'question_111': [22, 'gpt4_22'],\n",
       " 'question_7': [23, 'gpt4_23'],\n",
       " 'question_135': [24, 'gpt4_24'],\n",
       " 'question_165': [25, 'gpt4_25'],\n",
       " 'question_114': [26, 'gpt4_26'],\n",
       " 'question_192': [27, 'gpt4_27'],\n",
       " 'question_16': [28, 'gpt4_28'],\n",
       " 'question_55': [29, 'gpt4_29'],\n",
       " 'question_11': [30, 'gpt4_30'],\n",
       " 'question_154': [31, 'gpt4_31'],\n",
       " 'question_98': [32, 'gpt4_32'],\n",
       " 'question_47': [33, 'gpt4_33'],\n",
       " 'question_184': [34, 'gpt4_34'],\n",
       " 'question_58': [35, 'gpt4_35'],\n",
       " 'question_96': [36, 'gpt4_36'],\n",
       " 'question_148': [37, 'gpt4_37'],\n",
       " 'question_168': [38, 'gpt4_38'],\n",
       " 'question_150': [39, 'gpt4_39'],\n",
       " 'question_76': [40, 'gpt4_40'],\n",
       " 'question_84': [41, 'gpt4_41'],\n",
       " 'question_161': [42, 'gpt4_42'],\n",
       " 'question_180': [43, 'gpt4_43'],\n",
       " 'question_125': [44, 'gpt4_44'],\n",
       " 'question_48': [45, 'gpt4_45'],\n",
       " 'question_127': [46, 'gpt4_46'],\n",
       " 'question_118': [47, 'gpt4_47'],\n",
       " 'question_44': [48, 'gpt4_48'],\n",
       " 'question_49': [49, 'gpt4_49'],\n",
       " 'question_169': [50, 'gpt4_50'],\n",
       " 'question_140': [51, 'gpt4_51'],\n",
       " 'question_86': [52, 'gpt4_52'],\n",
       " 'question_137': [53, 'gpt4_53'],\n",
       " 'question_53': [54, 'gpt4_54'],\n",
       " 'question_32': [55, 'gpt4_55'],\n",
       " 'question_157': [56, 'gpt4_56'],\n",
       " 'question_28': [57, 'gpt4_57'],\n",
       " 'question_113': [58, 'gpt4_58'],\n",
       " 'question_170': [59, 'gpt4_59'],\n",
       " 'question_73': [60, 'gpt4_60'],\n",
       " 'question_74': [61, 'gpt4_61'],\n",
       " 'question_88': [62, 'gpt4_62'],\n",
       " 'question_181': [63, 'gpt4_63'],\n",
       " 'question_162': [64, 'gpt4_64'],\n",
       " 'question_77': [65, 'gpt4_65'],\n",
       " 'question_196': [66, 'gpt4_66'],\n",
       " 'question_183': [67, 'gpt4_67'],\n",
       " 'question_175': [68, 'gpt4_68'],\n",
       " 'question_191': [69, 'gpt4_69'],\n",
       " 'question_21': [70, 'gpt4_70'],\n",
       " 'question_15': [71, 'gpt4_71'],\n",
       " 'question_83': [72, 'gpt4_72'],\n",
       " 'question_104': [73, 'gpt4_73'],\n",
       " 'question_17': [74, 'gpt4_74'],\n",
       " 'question_94': [75, 'gpt4_75'],\n",
       " 'question_105': [76, 'gpt4_76'],\n",
       " 'question_110': [77, 'gpt4_77'],\n",
       " 'question_66': [78, 'gpt4_78'],\n",
       " 'question_33': [79, 'gpt4_79'],\n",
       " 'question_45': [80, 'gpt4_80'],\n",
       " 'question_72': [81, 'gpt4_81'],\n",
       " 'question_20': [82, 'gpt4_82'],\n",
       " 'question_99': [83, 'gpt4_83'],\n",
       " 'question_79': [84, 'gpt4_84'],\n",
       " 'question_14': [85, 'gpt4_85'],\n",
       " 'question_189': [86, 'gpt4_86'],\n",
       " 'question_143': [87, 'gpt4_87'],\n",
       " 'question_60': [88, 'gpt4_88'],\n",
       " 'question_198': [89, 'gpt4_89'],\n",
       " 'question_9': [90, 'gpt4_90'],\n",
       " 'question_159': [91, 'gpt4_91'],\n",
       " 'question_56': [92, 'gpt4_92'],\n",
       " 'question_145': [93, 'gpt4_93'],\n",
       " 'question_3': [94, 'gpt4_94'],\n",
       " 'question_23': [95, 'gpt4_95'],\n",
       " 'question_31': [96, 'gpt4_96'],\n",
       " 'question_91': [97, 'gpt4_97'],\n",
       " 'question_2': [98, 'gpt4_98'],\n",
       " 'question_103': [99, 'gpt4_99']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_positions = {}\n",
    "for n in range(len(gpt4_answers)):\n",
    "    d = gpt4_answers[n]\n",
    "    q_id = d['question_id']\n",
    "    questions_positions[q_id] = [n, d['answer_id']]\n",
    "questions_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotator1\n",
      "batch_1\n",
      "question_161\n",
      "question_101\n",
      "question_30\n",
      "batch_2\n",
      "question_118\n",
      "question_47\n",
      "question_52\n",
      "batch_3\n",
      "question_163\n",
      "question_190\n",
      "question_120\n",
      "batch_4\n",
      "question_76\n",
      "question_148\n",
      "question_16\n",
      "batch_5\n",
      "question_111\n",
      "question_127\n",
      "question_165\n",
      "batch_6\n",
      "question_199\n",
      "question_98\n",
      "question_78\n",
      "batch_7\n",
      "question_125\n",
      "question_24\n",
      "question_156\n",
      "batch_8\n",
      "question_117\n",
      "question_44\n",
      "annotator2\n",
      "batch_1\n",
      "question_55\n",
      "question_4\n",
      "question_199\n",
      "batch_2\n",
      "question_114\n",
      "question_112\n",
      "question_150\n",
      "batch_3\n",
      "question_16\n",
      "question_98\n",
      "question_117\n",
      "batch_4\n",
      "question_161\n",
      "question_71\n",
      "question_30\n",
      "batch_5\n",
      "question_111\n",
      "question_24\n",
      "question_49\n",
      "batch_6\n",
      "question_180\n",
      "question_135\n",
      "question_125\n",
      "batch_7\n",
      "question_8\n",
      "question_96\n",
      "question_120\n",
      "batch_8\n",
      "question_95\n",
      "question_78\n",
      "annotator3\n",
      "batch_1\n",
      "question_196\n",
      "question_72\n",
      "question_113\n",
      "batch_2\n",
      "question_74\n",
      "question_20\n",
      "question_33\n",
      "batch_3\n",
      "question_15\n",
      "question_159\n",
      "question_110\n",
      "batch_4\n",
      "question_94\n",
      "question_23\n",
      "question_73\n",
      "batch_5\n",
      "question_99\n",
      "question_104\n",
      "question_2\n",
      "batch_6\n",
      "question_83\n",
      "question_191\n",
      "question_143\n",
      "batch_7\n",
      "question_77\n",
      "question_17\n",
      "question_103\n",
      "batch_8\n",
      "question_53\n",
      "question_140\n",
      "annotator4\n",
      "batch_1\n",
      "question_66\n",
      "question_175\n",
      "question_28\n",
      "batch_2\n",
      "question_73\n",
      "question_169\n",
      "question_31\n",
      "batch_3\n",
      "question_53\n",
      "question_86\n",
      "question_145\n",
      "batch_4\n",
      "question_56\n",
      "question_140\n",
      "question_45\n",
      "batch_5\n",
      "question_33\n",
      "question_83\n",
      "question_104\n",
      "batch_6\n",
      "question_162\n",
      "question_14\n",
      "question_143\n",
      "batch_7\n",
      "question_159\n",
      "question_191\n",
      "question_183\n",
      "batch_8\n",
      "question_189\n",
      "question_72\n",
      "annotator5\n",
      "batch_1\n",
      "question_143\n",
      "question_88\n",
      "question_79\n",
      "batch_2\n",
      "question_189\n",
      "question_94\n",
      "question_74\n",
      "batch_3\n",
      "question_14\n",
      "question_32\n",
      "question_83\n",
      "batch_4\n",
      "question_137\n",
      "question_181\n",
      "question_3\n",
      "batch_5\n",
      "question_72\n",
      "question_196\n",
      "question_198\n",
      "batch_6\n",
      "question_66\n",
      "question_159\n",
      "question_91\n",
      "batch_7\n",
      "question_28\n",
      "question_140\n",
      "question_183\n",
      "batch_8\n",
      "question_175\n",
      "question_113\n",
      "annotator6\n",
      "batch_1\n",
      "question_96\n",
      "question_52\n",
      "question_117\n",
      "batch_2\n",
      "question_59\n",
      "question_190\n",
      "question_125\n",
      "batch_3\n",
      "question_111\n",
      "question_58\n",
      "question_101\n",
      "batch_4\n",
      "question_131\n",
      "question_71\n",
      "question_180\n",
      "batch_5\n",
      "question_118\n",
      "question_156\n",
      "question_114\n",
      "batch_6\n",
      "question_150\n",
      "question_192\n",
      "question_161\n",
      "batch_7\n",
      "question_199\n",
      "question_11\n",
      "question_163\n",
      "batch_8\n",
      "question_139\n",
      "question_24\n"
     ]
    }
   ],
   "source": [
    "for annotator, batches in fine_questions_batches.items():\n",
    "    print(annotator)\n",
    "    for batch_id, questions in batches.items():\n",
    "        print(batch_id)\n",
    "        for question_id in questions:\n",
    "            print(question_id)\n",
    "            n  = questions_positions[question_id][0]\n",
    "                \n",
    "            qa_pairs = [gpt4_answers[n], llama_answers[n], physician_answers[n]] # Randomizing answer type order\n",
    "            random.shuffle(qa_pairs)\n",
    "            \n",
    "            if qa_pairs[0]['question_id'] == qa_pairs[1]['question_id'] == qa_pairs[2]['question_id']:\n",
    "            \n",
    "                for qa_pair in qa_pairs:\n",
    "                    \n",
    "                    if qa_pair['answer_id'] in new_wrong_ones.keys():\n",
    "                        key = qa_pair['answer_id']\n",
    "                        sentences = new_wrong_ones[key]\n",
    "                    \n",
    "                    else:\n",
    "                        sentences = bold_sentences(qa_pair['answer'])\n",
    "                    \n",
    "                    if len(sentences) >= 6:\n",
    "                        sampled = random.sample(sentences, 6)\n",
    "                    else:\n",
    "                        sampled = sentences\n",
    "                    \n",
    "                    for sentence in sampled:\n",
    "                        new_d = qa_pair.copy()\n",
    "                        new_d['annotation_type'] = 'fine'\n",
    "                        new_d['rated'] = 'No'\n",
    "                        new_d['batch_id'] = batch_id\n",
    "                        new_d['sentence_id'] = new_d['answer_id'] + f'_{sentence[0]}'\n",
    "                        new_d['answer'] = sentence[1]\n",
    "                        with open(os.path.join(output_dir, 'all', f'{annotator.lower()}_fine2_sampled.jsonl'), 'a') as file:\n",
    "                            json.dump(new_d, file)\n",
    "                            file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pilot batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['llama_19_11', 'llama_19_3', 'llama_19_5', 'llama_19_7', 'llama_19_9']\n",
    "dictionaries = []\n",
    "for i in l:\n",
    "    d = {'sentence_id': i}\n",
    "    dictionaries.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries_dict = {'bibib': dictionaries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sentence_id': 'llama_19_3'},\n",
       " {'sentence_id': 'llama_19_5'},\n",
       " {'sentence_id': 'llama_19_7'},\n",
       " {'sentence_id': 'llama_19_9'},\n",
       " {'sentence_id': 'llama_19_11'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dictionaries_dict['bibib'], key=lambda x: int(x['sentence_id'].split('_')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_ids_per_batch = 3\n",
    "\n",
    "for annotation_type in ['coarse']:#,'fine']:\n",
    "    \n",
    "    with open(os.path.join(output_dir, 'pilot', f\"pilot_{annotation_type}.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "        data = [json.loads(line) for line in jsonl_file]\n",
    "    \n",
    "    if annotation_type == 'coarse':\n",
    "        data = data[9:18]\n",
    "    else:\n",
    "        data = data[:51]\n",
    "\n",
    "    batch_ids = set()\n",
    "    id_n = \"X\"\n",
    "    batch_id = f'batch_{id_n}'\n",
    "\n",
    "    for d in data:\n",
    "        \n",
    "        if d['question_id'] not in batch_ids and len(batch_ids) == question_ids_per_batch:\n",
    "            batch_ids = set()\n",
    "            id_n += 1\n",
    "            batch_id = f'batch_{id_n}'\n",
    "            \n",
    "        d['batch_id'] = batch_id\n",
    "    \n",
    "    for d in data:\n",
    "        with open(os.path.join(output_dir, 'pilot', f'pilot2_coarse.jsonl'), 'a') as file:\n",
    "            json.dump(d, file)\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, 'pilot', f\"pilot1_fine_old.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    data = [json.loads(line) for line in jsonl_file]\n",
    "    \n",
    "    for d in data:\n",
    "        d['batch_id'] = 'batch_0'\n",
    "        with open(os.path.join(output_dir, 'pilot', f'pilot1_fine.jsonl'), 'a') as file:\n",
    "            json.dump(d, file)\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-17 18:52:38.938 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-17 18:52:38.938 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['llama_42', 'llama_42', 'llama_42', 'llama_42', 'gpt4_42', 'gpt4_42', 'gpt4_42', 'physician_42', 'physician_42', 'physician_42', 'physician_42', 'physician_6', 'physician_6', 'physician_6', 'physician_6', 'llama_6', 'llama_6', 'llama_6', 'llama_6', 'llama_6', 'llama_6', 'gpt4_6', 'gpt4_6', 'gpt4_6', 'gpt4_6', 'gpt4_19', 'gpt4_19', 'gpt4_19', 'gpt4_19', 'gpt4_19', 'gpt4_19', 'llama_19', 'llama_19', 'llama_19', 'llama_19', 'llama_19', 'llama_19', 'physician_19', 'physician_19', 'physician_19', 'physician_19', 'physician_19']\n",
      "['physician_6', 'physician_6', 'gpt4_19', 'physician_42', 'gpt4_6', 'llama_19', 'gpt4_6', 'llama_6', 'gpt4_6', 'gpt4_42', 'llama_42', 'gpt4_6', 'llama_42', 'gpt4_19', 'gpt4_19', 'llama_19', 'physician_42', 'llama_6', 'physician_19', 'physician_42', 'gpt4_19', 'llama_6', 'llama_19', 'gpt4_42', 'llama_19', 'physician_19', 'gpt4_42', 'llama_19', 'gpt4_19', 'llama_6', 'physician_19', 'llama_19', 'llama_6', 'physician_42', 'physician_6', 'llama_6', 'gpt4_19', 'llama_42', 'physician_19', 'physician_6', 'llama_42', 'physician_19']\n",
      "physician_6_0\n",
      "physician_6_1\n",
      "physician_6_2\n",
      "physician_6_3\n",
      "gpt4_19_3\n",
      "gpt4_19_6\n",
      "gpt4_19_7\n",
      "gpt4_19_8\n",
      "gpt4_19_10\n",
      "gpt4_19_12\n",
      "physician_42_0\n",
      "physician_42_1\n",
      "physician_42_2\n",
      "physician_42_3\n",
      "gpt4_6_0\n",
      "gpt4_6_1\n",
      "gpt4_6_2\n",
      "gpt4_6_3\n",
      "llama_19_1\n",
      "llama_19_2\n",
      "llama_19_3\n",
      "llama_19_7\n",
      "llama_19_9\n",
      "llama_19_10\n",
      "llama_6_0\n",
      "llama_6_1\n",
      "llama_6_2\n",
      "llama_6_4\n",
      "llama_6_5\n",
      "llama_6_6\n",
      "gpt4_42_0\n",
      "gpt4_42_1\n",
      "gpt4_42_2\n",
      "llama_42_0\n",
      "llama_42_1\n",
      "llama_42_2\n",
      "llama_42_3\n",
      "physician_19_0\n",
      "physician_19_1\n",
      "physician_19_2\n",
      "physician_19_3\n",
      "physician_19_4\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import pymongo\n",
    "from pymongo.mongo_client import MongoClient\n",
    "import streamlit as st\n",
    "\n",
    "uri = f\"mongodb+srv://{open(os.path.join('..', '..', 'PhD', 'apikeys', 'mongodb_clinicalqa_uri.txt')).read().strip()}/?retryWrites=true&w=majority&appName=clinicalqa\"\n",
    "client = MongoClient(uri)  # Create a new client and connect to the server\n",
    "db = client[\"fine2\"]  # TEST DATABASE DO NOT CHANGE\n",
    "annotator_n = '1'\n",
    "batch_n = '1'\n",
    "\n",
    "# annotator_n is the key used to access which set of annotations\n",
    "# b/c we inserted based on annotator# in upload.py\n",
    "annotations_collection = st.session_state.annotation_collection = db[\n",
    "    f\"annotator{annotator_n}\"\n",
    "]\n",
    "\n",
    "mongodb_result = [\n",
    "    i\n",
    "    for i in annotations_collection.find(\n",
    "        {\"$and\": [{\"rated\": \"No\"}, {\"batch_id\": f\"batch_{batch_n}\"}]}\n",
    "    )\n",
    "]  # check if any fine annotations left\n",
    "print([d['answer_id'] for d in mongodb_result])\n",
    "random.shuffle(mongodb_result)\n",
    "print([d['answer_id'] for d in mongodb_result])\n",
    "\n",
    "grouped = OrderedDict()\n",
    "for item in mongodb_result:\n",
    "    answer_id = item['answer_id']\n",
    "    if answer_id not in grouped:\n",
    "        grouped[answer_id] = []\n",
    "    grouped[answer_id].append(item)\n",
    "    \n",
    "for aid in grouped:\n",
    "    grouped[aid] = sorted(grouped[aid], key=lambda x: int(x['sentence_id'].split('_')[-1]))\n",
    "\n",
    "clean_responses_todo = [item for group in grouped.values() for item in group]\n",
    "\n",
    "for d in clean_responses_todo:\n",
    "    print(d['sentence_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['llama_6', 'physician_19', 'gpt4_42', 'llama_6', 'llama_6', 'llama_42', 'llama_6', 'gpt4_19', 'llama_42', 'physician_19', 'gpt4_6', 'gpt4_42', 'llama_42', 'gpt4_6', 'llama_19', 'physician_19', 'gpt4_19', 'llama_6', 'gpt4_19', 'physician_19', 'llama_42', 'gpt4_19', 'physician_6', 'physician_19', 'physician_6', 'gpt4_6', 'gpt4_19', 'llama_19', 'physician_42', 'llama_6', 'gpt4_6', 'gpt4_19', 'physician_42', 'physician_6', 'llama_19', 'physician_42', 'llama_19', 'llama_19', 'physician_42', 'llama_19', 'gpt4_42', 'physician_6']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
